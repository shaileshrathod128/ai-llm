## ğŸ“¦ Examples Included

This repository contains two complete, production-ready LangChain demos to showcase different real-world use cases:

---

### ğŸ” 1. `rag-pipeline/` â€“ Retrieval-Augmented Generation (RAG) Demo

Build an LLM-powered assistant that answers domain-specific questions by retrieving relevant content from your own knowledge base using:

- ğŸ§  LangChain
- ğŸ“š FAISS vector search
- ğŸ¤– OpenAI (or any LLM)

**Use Case:**

> â€œAsk questions over your company policies, PDF docs, or knowledge base with factual, grounded answers.â€

ğŸ“‚ [View `rag-pipeline`](./rag-pipeline)

---

### ğŸ¤– 2. `langchain-agents/` â€“ Multi-Model LangChain Agent

Create an AI assistant that dynamically chooses between models based on the type of user query:

- ğŸ” General Q&A â†’ OpenAI
- ğŸ“ Summarization â†’ Mistral (via Replicate)

**Use Case:**

> â€œAutomatically route summarization tasks to Mistral and general questions to OpenAI.â€

ğŸ“‚ [View `langchain-agents`](./langchain-agents)

---

Both demos follow best practices, support `.env` secrets, and are great starting points for real-world GenAI applications.
